{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92de8ca4-7181-45f5-9980-b723d2566f5e",
   "metadata": {},
   "source": [
    "# Challenge Prompting\n",
    "\n",
    "Resolver los siguientes ejercicios dejando el codigo con su ejecucion.\n",
    "\n",
    "Importar las librerias necesarias y **correr las celdas para visualizar el resultado en cada ejercicio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bbb09-0f5a-4e97-9a06-2361c5cdd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bloque importacion de librerias\n",
    "\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e004e5b7-b704-4592-b8b4-b01b8d6687cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o5bIcLwjlqD1zhLOd4jPC0nu8ulknRgJMigWt0mD\n"
     ]
    }
   ],
   "source": [
    "## bloque variables de entorno\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Load .env file\n",
    "\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "print(api_key)  # Verify the key is loaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd6745ff-cd45-4231-b3d6-518954a9ffca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\OneDrive\\Escritorio\\challenge_prompting_notekook\\venv\\Lib\\site-packages\\cohere\\core\\pydantic_utilities.py:13: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.datetime_parse import parse_date as parse_date\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='e92c903f-9fdc-4fb8-b57d-2310250bd9b5' finish_reason='COMPLETE' message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=204.0, output_tokens=9.0), cached_tokens=192.0) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "## bloque conexion a Cohere\n",
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "# alternativa:\n",
    "# co = cohere.ClientV2(api_key)\n",
    "\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}],\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacdb26-ce51-49cc-b37f-5aa45c09ff51",
   "metadata": {},
   "source": [
    "## Ejercicio 1\n",
    "\n",
    "Extraccion de entidades\n",
    "\n",
    "Utilizar el LLM para extraer las siguientes entidades del texto medico.\n",
    "\n",
    "- Paciente:\n",
    "    - Nombre\n",
    "    - Edad\n",
    "- Fecha de admisi√≥n\n",
    "- S√≠ntomas\n",
    "- Diagn√≥stico\n",
    "- Tratamiento recomendado\n",
    "\n",
    "**Aclaracion:** \n",
    "\n",
    "La salida tiene que ser un **string con formato de tipo json**, el cual se convertira en un diccionario de Python.\n",
    "\n",
    "Si la linea de conversion en test da error el ejercicio no esta completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e43d7-b074-4973-9cd0-5a6fbe816084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo \n",
    "\n",
    "# texto a analizar\n",
    "\"\"\"La paciente, Mar√≠a Gonz√°lez, de 45 a√±os, fue admitida en el Hospital Central el 5 de agosto de 2023 debido a s√≠ntomas de fatiga cr√≥nica y dolores musculares./\n",
    "Tras una serie de an√°lisis, se diagnostic√≥ fibromialgia. La doctora a cargo, Laura Ram√≠rez, recomend√≥ un tratamiento basado en fisioterapia y medicamentos analg√©sicos. /\n",
    "La pr√≥xima consulta est√° programada para el 15 de septiembre.\"\"\"\n",
    "\n",
    "\n",
    "# respuesta del LLM\n",
    "{\n",
    "  \"paciente\": {\n",
    "    \"nombre\": \"Mar√≠a Gonz√°lez\",\n",
    "    \"edad\": 45\n",
    "  },\n",
    "  \"fecha_admision\": \"2023-08-05\",\n",
    "  \"sintomas\": [\n",
    "    \"fatiga cr√≥nica\",\n",
    "    \"dolores musculares\"\n",
    "  ],\n",
    "  \"diagnostico\": \"fibromialgia\",\n",
    "  \"tratamiento\": [\n",
    "    \"fisioterapia\",\n",
    "    \"medicamentos analg√©sicos\"\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac8d0a6-db5c-4eec-9f71-89e60ceaf914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "425cffab-9efd-4d80-bc64-6ef69ce233e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_to_analize = \"\"\"Sof√≠a L√≥pez, de 28 a√±os, ingres√≥ al Hospital Infantil el 3 de abril de 2023 debido a fiebre alta y tos persistente./\n",
    "Despu√©s de varias pruebas, se le diagnostic√≥ neumon√≠a. La pediatra responsable, Dra. Claudia Torres, indic√≥ tratamiento con antibi√≥ticos y reposo./\n",
    "La pr√≥xima evaluaci√≥n ser√° el 10 de abril.\"\"\"\n",
    "\n",
    "# Texto 1 - Formato narrativo desordenado\n",
    "text_to_analize_1 = \"\"\"Tras sufrir una ca√≠da en su domicilio, el se√±or Roberto Jim√©nez, quien cuenta con setenta y dos a√±os de edad, \n",
    "fue trasladado de urgencia al Centro de Traumatolog√≠a. Presentaba dolor intenso en la cadera izquierda. \n",
    "La fecha de ingreso fue 14-Feb-2024. Radiograf√≠as confirmaron fractura de f√©mur. \n",
    "El tratamiento indicado por el Dr. Mendoza incluye cirug√≠a programada y analgesia. \n",
    "Su pr√≥xima valoraci√≥n ser√° dentro de 15 d√≠as.\"\"\"\n",
    "\n",
    "# Texto 2 - Formato telegr√°fico con datos mezclados\n",
    "text_to_analize_2 = \"\"\"INGRESO: 2023/12/08 - Paciente: Laura, 19 a√±os. \n",
    "Motivo consulta: cefalea intensa + fotofobia + n√°useas. \n",
    "Establecido diagn√≥stico: migra√±a con aura. \n",
    "M√©dico tratante: Dra. Silva. \n",
    "Plan: triptanes + reposo en habitaci√≥n oscura. \n",
    "Pr√≥ximo control: 20 de diciembre 2023.\"\"\"\n",
    "\n",
    "# Texto 3 - Formato con datos al final y edad en palabras\n",
    "text_to_analize_3 = \"\"\"Acude a consulta externa por presentar lesiones en mucosa oral y dificultad para tragar. \n",
    "Se realiza biopsia que confirma diagn√≥stico de estomatitis aftosa severa. \n",
    "Se pauta tratamiento con enjuagues bucales medicados y corticoides t√≥picos. \n",
    "La paciente se llama Carmen R√≠os, tiene cuarenta y siete a√±os. \n",
    "Fecha de la consulta: marzo 5, 2024. \n",
    "Seguimiento en un mes.\"\"\"\n",
    "\n",
    "# Texto 4 - Formato con datos entremezclados y fecha en texto completo\n",
    "text_to_analize_4 = \"\"\"En el d√≠a de hoy, diez de agosto del dos mil veintitr√©s, \n",
    "recibimos al ni√±o Miguel √Ångel Santos, de 8 a√±os de edad, \n",
    "por cuadro de fiebre de 39¬∞C y erupci√≥n cut√°nea maculopapular. \n",
    "Confirmado diagn√≥stico de varicela mediante test espec√≠fico. \n",
    "La pediatra Daniela Ortiz recomienda aislamiento y antipir√©ticos. \n",
    "Pr√≥xima revisi√≥n: cuando desaparezcan las lesiones.\"\"\"\n",
    "\n",
    "# Texto 5 - Formato muy desestructurado con datos incompletos\n",
    "text_to_analize_5 = \"\"\"Paciente femenina, nombre: Patricia Navarro. Edad: treinta y un a√±os. \n",
    "S√≠ntomas referidos: dolor abdominal en hipogastrio, disuria. \n",
    "Examen de orina positivo para infecci√≥n. \n",
    "Diagn√≥stico: cistitis aguda. \n",
    "Atendida en Sala de Emergencias el 30/06/2024. \n",
    "Tratamiento instaurado: antibi√≥tico (nitrofuranto√≠na) y aumento de ingesta h√≠drica. \n",
    "Volver a consultar si persisten s√≠ntomas.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ff6d292-d4cb-4484-811e-d0d641c66d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Sof√≠a L√≥pez\",\n",
      "        \"edad\": 28\n",
      "    },\n",
      "    \"fecha_admision\": \"2023-04-03\",\n",
      "    \"sintomas\": [\n",
      "        \"fiebre alta\",\n",
      "        \"tos persistente\"\n",
      "    ],\n",
      "    \"diagnostico\": \"neumon√≠a\",\n",
      "    \"tratamiento\": [\n",
      "        \"antibi√≥ticos\",\n",
      "        \"reposo\"\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Roberto Jim√©nez\",\n",
      "        \"edad\": 72\n",
      "    },\n",
      "    \"fecha_admision\": \"2024-02-14\",\n",
      "    \"sintomas\": [\n",
      "        \"Dolor intenso en la cadera izquierda\"\n",
      "    ],\n",
      "    \"diagnostico\": \"Fractura de f√©mur\",\n",
      "    \"tratamiento\": [\n",
      "        \"Cirug√≠a programada\",\n",
      "        \"Analgesia\"\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Laura\",\n",
      "        \"edad\": 19\n",
      "    },\n",
      "    \"fecha_admision\": \"2023-12-08\",\n",
      "    \"sintomas\": [\n",
      "        \"cefalea intensa\",\n",
      "        \"fotofobia\",\n",
      "        \"n√°useas\"\n",
      "    ],\n",
      "    \"diagnostico\": \"migra√±a con aura\",\n",
      "    \"tratamiento\": [\n",
      "        \"triptanes\",\n",
      "        \"reposo en habitaci√≥n oscura\"\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Carmen R√≠os\",\n",
      "        \"edad\": 47\n",
      "    },\n",
      "    \"fecha_admision\": \"2024-03-05\",\n",
      "    \"sintomas\": [\n",
      "        \"Lesiones en mucosa oral\",\n",
      "        \"Dificultad para tragar\"\n",
      "    ],\n",
      "    \"diagnostico\": \"Estomatitis aftosa severa\",\n",
      "    \"tratamiento\": [\n",
      "        \"Enjuagues bucales medicados\",\n",
      "        \"Corticoides t√≥picos\"\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Miguel √Ångel Santos\",\n",
      "        \"edad\": 8\n",
      "    },\n",
      "    \"fecha_admision\": \"2023-08-10\",\n",
      "    \"sintomas\": [\n",
      "        \"Fiebre de 39¬∞C\",\n",
      "        \"Erupci√≥n cut√°nea maculopapular\"\n",
      "    ],\n",
      "    \"diagnostico\": \"Varicela\",\n",
      "    \"tratamiento\": [\n",
      "        \"Aislamiento\",\n",
      "        \"Antipir√©ticos\"\n",
      "    ]\n",
      "}\n",
      "{\n",
      "    \"paciente\": {\n",
      "        \"nombre\": \"Patricia Navarro\",\n",
      "        \"edad\": 31\n",
      "    },\n",
      "    \"fecha_admision\": \"2024-06-30\",\n",
      "    \"sintomas\": [\n",
      "        \"dolor abdominal en hipogastrio\",\n",
      "        \"disuria\"\n",
      "    ],\n",
      "    \"diagnostico\": \"cistitis aguda\",\n",
      "    \"tratamiento\": [\n",
      "        \"antibi√≥tico (nitrofuranto√≠na)\",\n",
      "        \"aumento de ingesta h√≠drica\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"Eres un asistente que extrae informaci√≥n m√©dica relevante de textos cl√≠nicos y la estructura en formato JSON.\n",
    "                \n",
    "                Instrucciones:\n",
    "                - Extrae solo la informaci√≥n clave del texto proporcionado\n",
    "                - Pres√©ntala en formato JSON estructurado\n",
    "                - No inventes informaci√≥n que no est√© en el texto\n",
    "                - Si no hay informaci√≥n disponible para alg√∫n campo, d√©jalo vac√≠o\n",
    "                - La edad solo debe ser un n√∫mero entero, por ejemplo \"edad\": 45\n",
    "                - El formato de fecha debe ser \"YYYY-MM-DD\", por ejemplo \"2023-08-05\"\n",
    "                \n",
    "                Formato requerido:\n",
    "                {\n",
    "                    \"paciente\": {\n",
    "                        \"nombre\": \"\",\n",
    "                        \"edad\": \n",
    "                    },\n",
    "                    \"fecha_admision\": \"\",\n",
    "                    \"sintomas\": [],\n",
    "                    \"diagnostico\": \"\",\n",
    "                    \"tratamiento\": []\n",
    "                }\"\"\"\n",
    "            },\n",
    "                {\"role\": \"user\", \"content\": f\"Por favor, extrae la informaci√≥n m√©dica del siguiente texto: {text_to_analize}\"}],\n",
    "    )\n",
    "\n",
    "json_response = response.message.content[0].text\n",
    "\n",
    "print(json_response)\n",
    "\n",
    "response_1 = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"Eres un asistente que extrae informaci√≥n m√©dica relevante de textos cl√≠nicos y la estructura en formato JSON.\n",
    "                \n",
    "                Instrucciones:\n",
    "                - Extrae solo la informaci√≥n clave del texto proporcionado\n",
    "                - Pres√©ntala en formato JSON estructurado\n",
    "                - No inventes informaci√≥n que no est√© en el texto\n",
    "                - Si no hay informaci√≥n disponible para alg√∫n campo, d√©jalo vac√≠o\n",
    "                - La edad solo debe ser un n√∫mero entero, por ejemplo \"edad\": 45\n",
    "                - El formato de fecha debe ser \"YYYY-MM-DD\", por ejemplo \"2023-08-05\"\n",
    "                \n",
    "                Formato requerido:\n",
    "                {\n",
    "                    \"paciente\": {\n",
    "                        \"nombre\": \"\",\n",
    "                        \"edad\": \n",
    "                    },\n",
    "                    \"fecha_admision\": \"\",\n",
    "                    \"sintomas\": [],\n",
    "                    \"diagnostico\": \"\",\n",
    "                    \"tratamiento\": []\n",
    "                }\"\"\"\n",
    "            },\n",
    "                {\"role\": \"user\", \"content\": f\"Por favor, extrae la informaci√≥n m√©dica del siguiente texto: {text_to_analize_1}\"}],\n",
    "    )\n",
    "\n",
    "json_response_1 = response_1.message.content[0].text\n",
    "\n",
    "print(json_response_1)\n",
    "\n",
    "response_2 = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"Eres un asistente que extrae informaci√≥n m√©dica relevante de textos cl√≠nicos y la estructura en formato JSON.\n",
    "                \n",
    "                Instrucciones:\n",
    "                - Extrae solo la informaci√≥n clave del texto proporcionado\n",
    "                - Pres√©ntala en formato JSON estructurado\n",
    "                - No inventes informaci√≥n que no est√© en el texto\n",
    "                - Si no hay informaci√≥n disponible para alg√∫n campo, d√©jalo vac√≠o\n",
    "                - La edad solo debe ser un n√∫mero entero, por ejemplo \"edad\": 45\n",
    "                - El formato de fecha debe ser \"YYYY-MM-DD\", por ejemplo \"2023-08-05\"\n",
    "                \n",
    "                Formato requerido:\n",
    "                {\n",
    "                    \"paciente\": {\n",
    "                        \"nombre\": \"\",\n",
    "                        \"edad\": \n",
    "                    },\n",
    "                    \"fecha_admision\": \"\",\n",
    "                    \"sintomas\": [],\n",
    "                    \"diagnostico\": \"\",\n",
    "                    \"tratamiento\": []\n",
    "                }\"\"\"\n",
    "            },\n",
    "                {\"role\": \"user\", \"content\": f\"Por favor, extrae la informaci√≥n m√©dica del siguiente texto: {text_to_analize_2}\"}],\n",
    "    )\n",
    "\n",
    "json_response_2 = response_2.message.content[0].text\n",
    "\n",
    "print(json_response_2)\n",
    "\n",
    "response_3 = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"Eres un asistente que extrae informaci√≥n m√©dica relevante de textos cl√≠nicos y la estructura en formato JSON.\n",
    "                \n",
    "                Instrucciones:\n",
    "                - Extrae solo la informaci√≥n clave del texto proporcionado\n",
    "                - Pres√©ntala en formato JSON estructurado\n",
    "                - No inventes informaci√≥n que no est√© en el texto\n",
    "                - Si no hay informaci√≥n disponible para alg√∫n campo, d√©jalo vac√≠o\n",
    "                - La edad solo debe ser un n√∫mero entero, por ejemplo \"edad\": 45\n",
    "                - El formato de fecha debe ser \"YYYY-MM-DD\", por ejemplo \"2023-08-05\"\n",
    "                \n",
    "                Formato requerido:\n",
    "                {\n",
    "                    \"paciente\": {\n",
    "                        \"nombre\": \"\",\n",
    "                        \"edad\": \n",
    "                    },\n",
    "                    \"fecha_admision\": \"\",\n",
    "                    \"sintomas\": [],\n",
    "                    \"diagnostico\": \"\",\n",
    "                    \"tratamiento\": []\n",
    "                }\"\"\"\n",
    "            },\n",
    "                {\"role\": \"user\", \"content\": f\"Por favor, extrae la informaci√≥n m√©dica del siguiente texto: {text_to_analize_3}\"}],\n",
    "    )\n",
    "\n",
    "json_response_3 = response_3.message.content[0].text\n",
    "\n",
    "print(json_response_3)\n",
    "\n",
    "response_4 = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"Eres un asistente que extrae informaci√≥n m√©dica relevante de textos cl√≠nicos y la estructura en formato JSON.\n",
    "                \n",
    "                Instrucciones:\n",
    "                - Extrae solo la informaci√≥n clave del texto proporcionado\n",
    "                - Pres√©ntala en formato JSON estructurado\n",
    "                - No inventes informaci√≥n que no est√© en el texto\n",
    "                - Si no hay informaci√≥n disponible para alg√∫n campo, d√©jalo vac√≠o\n",
    "                - La edad solo debe ser un n√∫mero entero, por ejemplo \"edad\": 45\n",
    "                - El formato de fecha debe ser \"YYYY-MM-DD\", por ejemplo \"2023-08-05\"\n",
    "                \n",
    "                Formato requerido:\n",
    "                {\n",
    "                    \"paciente\": {\n",
    "                        \"nombre\": \"\",\n",
    "                        \"edad\": \n",
    "                    },\n",
    "                    \"fecha_admision\": \"\",\n",
    "                    \"sintomas\": [],\n",
    "                    \"diagnostico\": \"\",\n",
    "                    \"tratamiento\": []\n",
    "                }\"\"\"\n",
    "            },\n",
    "                {\"role\": \"user\", \"content\": f\"Por favor, extrae la informaci√≥n m√©dica del siguiente texto: {text_to_analize_4}\"}],\n",
    "    )\n",
    "\n",
    "json_response_4 = response_4.message.content[0].text\n",
    "\n",
    "print(json_response_4)\n",
    "\n",
    "response_5 = co.chat(\n",
    "    model=\"command-r-plus-08-2024\",\n",
    "    messages=[{\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"\"\"Eres un asistente que extrae informaci√≥n m√©dica relevante de textos cl√≠nicos y la estructura en formato JSON.\n",
    "                \n",
    "                Instrucciones:\n",
    "                - Extrae solo la informaci√≥n clave del texto proporcionado\n",
    "                - Pres√©ntala en formato JSON estructurado\n",
    "                - No inventes informaci√≥n que no est√© en el texto\n",
    "                - Si no hay informaci√≥n disponible para alg√∫n campo, d√©jalo vac√≠o\n",
    "                - La edad solo debe ser un n√∫mero entero, por ejemplo \"edad\": 45\n",
    "                - El formato de fecha debe ser \"YYYY-MM-DD\", por ejemplo \"2023-08-05\"\n",
    "                \n",
    "                Formato requerido:\n",
    "                {\n",
    "                    \"paciente\": {\n",
    "                        \"nombre\": \"\",\n",
    "                        \"edad\": \n",
    "                    },\n",
    "                    \"fecha_admision\": \"\",\n",
    "                    \"sintomas\": [],\n",
    "                    \"diagnostico\": \"\",\n",
    "                    \"tratamiento\": []\n",
    "                }\"\"\"\n",
    "            },\n",
    "                {\"role\": \"user\", \"content\": f\"Por favor, extrae la informaci√≥n m√©dica del siguiente texto: {text_to_analize_5}\"}],\n",
    "    )\n",
    "\n",
    "json_response_5 = response_5.message.content[0].text\n",
    "\n",
    "print(json_response_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f6f0009-8a9c-49a3-b740-d73e0dbe765e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTS AUTOM√ÅTICOS\n",
      "==================================================\n",
      "Texto Original: EXITOSO\n",
      "Texto 1: EXITOSO\n",
      "Texto 2: EXITOSO\n",
      "Texto 3: EXITOSO\n",
      "Texto 4: EXITOSO\n",
      "Texto 5: EXITOSO\n",
      "==================================================\n",
      "RESULTADO: 6/6 tests exitosos\n",
      "EFECTIVIDAD: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "# final_result = json.loads(llm_response)\n",
    "import cohere\n",
    "import json\n",
    "\n",
    "# Diccionario con todas las respuestas\n",
    "respuestas = {\n",
    "    \"Texto Original\": json_response,\n",
    "    \"Texto 1\": json_response_1,\n",
    "    \"Texto 2\": json_response_2,\n",
    "    \"Texto 3\": json_response_3, \n",
    "    \"Texto 4\": json_response_4,\n",
    "    \"Texto 5\": json_response_5\n",
    "}\n",
    "\n",
    "print(\"TESTS AUTOM√ÅTICOS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "exitosos = 0\n",
    "totales = len(respuestas)\n",
    "\n",
    "for nombre, respuesta in respuestas.items():\n",
    "    try:\n",
    "        # Limpiar respuesta\n",
    "        respuesta_limpia = respuesta\n",
    "        if \"```json\" in respuesta_limpia:\n",
    "            respuesta_limpia = respuesta_limpia.split(\"```json\")[1].split(\"```\")[0].strip()\n",
    "        elif \"```\" in respuesta_limpia:\n",
    "            respuesta_limpia = respuesta_limpia.split(\"```\")[1].split(\"```\")[0].strip()\n",
    "        \n",
    "        # Test\n",
    "        final_result = json.loads(respuesta_limpia)\n",
    "        print(f\"{nombre}: EXITOSO\")\n",
    "        exitosos += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{nombre}: FALLIDO - {e}\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"RESULTADO: {exitosos}/{totales} tests exitosos\")\n",
    "print(f\"EFECTIVIDAD: {(exitosos/totales)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ee190-faca-46d8-9c11-0f8904bd1752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0e72e5-3bd5-4f26-860c-340e25e72f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b37fbf25-6db4-432a-82c4-2e7edce27686",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "Tenemos dos funciones en Python, una llamada *'add_contact'* y otra llamada *'get_information'*.\n",
    "\n",
    "**Utilizar algun LLM que permita funtion calling** y desarrollar un codigo secuencial automatico que consiga:\n",
    "\n",
    "Interpretar la consulta del usuario, identificar a que funcion llamar, luego llamarla (si es que aplica) y darle una respuesta final al usuario.  (usar function calling para esta solucion)\n",
    "\n",
    "La entrada a dicho codigo es la consulta del usuario, a continuacion algunos ejemplos:\n",
    "\n",
    "- \"Agrega a Juan P√©rez con el n√∫mero 555-1234 y el correo juanperez@mail.com.\"\n",
    "- \"Guarda a Luc√≠a G√≥mez en mis contactos. Su tel√©fono es 555-5678 y su email es lucia.gomez@gmail.com.\"\n",
    "- \"Cual es el Email de Juan P√©rez.?\"\n",
    "\n",
    "Salidas esperadas de dichos ejemplos (variaran porque las genera el LLM):\n",
    "-  El contacto fue anadido con exito\n",
    "-  Se anadio el contacto\n",
    "-  El email de juan perez es juanperez@mail.com\n",
    "\n",
    "Link de ayuda: https://github.com/cohere-ai/notebooks/blob/main/notebooks/agents/Vanilla_Tool_Use_v2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6e43cb9-5e6a-4807-9818-c85408f1ba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "contacts = {\n",
    "    'Joaquin Lopez':{'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'},\n",
    "    'Flavio Oncativo':{'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}\n",
    "}\n",
    "\n",
    "def add_contact(name, tel, mail):\n",
    "    \"\"\"\n",
    "    Agrega un contacto al diccionario.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "        phone (str): N√∫mero de tel√©fono del contacto.\n",
    "        email (str): Correo electr√≥nico del contacto.\n",
    "    Retorna:\n",
    "        str: Mensaje confirmando la adici√≥n del contacto.\n",
    "    \"\"\"\n",
    "    contacts[name] = {'tel': tel, 'mail': mail}\n",
    "    return \"Contacto a√±adido con √©xito.\"\n",
    "\n",
    "def get_information(name):\n",
    "    \"\"\"\n",
    "    Recupera la informaci√≥n de un contacto.\n",
    "    Par√°metros:\n",
    "        name (str): Nombre del contacto.\n",
    "    Retorna:\n",
    "        dict/str: Informaci√≥n del contacto o un mensaje si no existe.\n",
    "    \"\"\"\n",
    "    if name in contacts:\n",
    "        return contacts[name]\n",
    "    else:\n",
    "        return \"Contacto no encontrado.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb79ea5-4ae3-4367-8213-8c38059b3f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d3bed9a-d5d1-49c3-b91b-8cd23bb9c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contacto no encontrado.\n",
      "Contacto a√±adido con √©xito.\n",
      "{'tel': '555-1234', 'mail': 'juanperez@mail.com'}\n"
     ]
    }
   ],
   "source": [
    "print(get_information(\"Juan P√©rez\"))\n",
    "\n",
    "print(add_contact(\"Juan P√©rez\", \"555-1234\", \"juanperez@mail.com\"))\n",
    "print(contacts[\"Juan P√©rez\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ddaf4d1-6ab9-4707-823d-11ada125b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos las tools para el LLM (https://docs.cohere.com/docs/tool-use-overview#system-message)\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"add_contact\",\n",
    "            \"description\": \"Agrega un contacto con nombre, tel√©fono y email.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre del contacto\"\n",
    "                    },\n",
    "                    \"tel\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"N√∫mero de tel√©fono\"\n",
    "                    },\n",
    "                    \"mail\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Correo electr√≥nico\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\", \"tel\", \"mail\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_information\",\n",
    "            \"description\": \"Obtiene la informaci√≥n de un contacto por nombre.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Nombre del contacto\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# Funci√≥n para consultar al LLM\n",
    "\n",
    "def consultar_llm(content_user):\n",
    "    response = co.chat(\n",
    "        model=\"command-r-plus-08-2024\",\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Tu tarea es interpretar las consultas del usuario y decidir, si corresponde, llamar alguna de las funciones disponibles mediante tool calling. No inventes datos, no completes informaci√≥n faltante y no agregues contactos con informaci√≥n inexistente.\n",
    "                Actu√° como un agente que administra contactos personales. Respond√© de forma breve, clara y siempre en espa√±ol.  \n",
    "                El usuario puede:\n",
    "                - Agregar un contacto.\n",
    "                - Consultar la informaci√≥n de un contacto.\n",
    "                No inventes tel√©fonos, correos ni nombres.  \n",
    "                No generes informaci√≥n sensible ni datos privados que el usuario no haya proporcionado expl√≠citamente.  \n",
    "                Si el usuario pide informaci√≥n que no existe en la agenda actual, respond√© que no se encuentra o utiliz√° la funci√≥n correspondiente para confirmarlo.  \n",
    "                No supongas datos incompletos.\n",
    "                Us√° exclusivamente la informaci√≥n provista por el usuario y las funciones disponibles.  \n",
    "                No uses conocimientos fuera del estado actual del diccionario de contactos.  \n",
    "                Si el usuario no brinda suficiente informaci√≥n para llamar a una funci√≥n, ped√≠ la informaci√≥n faltante.\n",
    "                La agenda de contactos es la siguiente: \"\"\" + str(contacts) + \"\"\"\n",
    "\n",
    "                Formatos aceptados:\n",
    "                - Para agregar: name, tel, mail\n",
    "                - Para consultar: name\n",
    "\n",
    "                Interpret√° cada consulta del usuario:  \n",
    "                1. Si es una acci√≥n sobre contactos, llam√° a la funci√≥n adecuada usando tool calling.  \n",
    "                2. Si no corresponde llamar a ninguna funci√≥n, respond√© con un mensaje breve y claro.  \n",
    "\n",
    "                No inventes informaci√≥n bajo ninguna circunstancia.\n",
    "\n",
    "                Responde usando exactamente este formato JSON (la respuesta debe ser generada como una cadena de texto, no agregues explicaciones de lo que vas a hacer para obtener la respuesta):\n",
    "                { \"respuesta\": \"\", \"citas_del_contexto\": :p }\n",
    "                \"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": content_user\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "        # Ejecutar el tool call para obtener datos\n",
    "    if response.message.tool_calls:\n",
    "        for call in response.message.tool_calls:\n",
    "            if call.function.name == \"get_information\":\n",
    "                args = json.loads(call.function.arguments)\n",
    "                contact_data = get_information(args['name'])\n",
    "                \n",
    "                # Segunda llamada - generar respuesta formateada\n",
    "                response2 = co.chat(\n",
    "                    model=\"command-r-plus-08-2024\",\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": f\"\"\"Genera una respuesta directa en espa√±ol usando este formato:\n",
    "                            - Si preguntan por tel√©fono: \"El tel√©fono de [nombre] es [tel]\"\n",
    "                            - Si preguntan por email: \"El email de [nombre] es [mail]\"\n",
    "                            - Si no existe: \"El contacto [nombre] no existe\"\n",
    "                            \n",
    "                            Datos obtenidos: {contact_data}\n",
    "                            Consulta del usuario: {content_user}\"\"\"\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": content_user\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                return response2\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "72ea0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para procesar la respuesta del LLM y decidir a que funcion llamar\n",
    "# Tenemos 2 casos para que funcione con diferentes modelos de LLM de cohere\n",
    "\n",
    "import json\n",
    "\n",
    "def procesar_respuesta(response):\n",
    "    message = response.message\n",
    "\n",
    "    if not message.tool_calls:\n",
    "        return message.content[0].text\n",
    "\n",
    "    for call in message.tool_calls:\n",
    "\n",
    "        # Caso 1 ‚Äî formato con function.name / function.arguments\n",
    "        if hasattr(call, \"function\") and call.function is not None:\n",
    "            name = call.function.name\n",
    "            args = json.loads(call.function.arguments)\n",
    "\n",
    "        # Caso 2 ‚Äî formato con name / parameters directo\n",
    "        else:\n",
    "            name = call.name\n",
    "            args = call.parameters\n",
    "\n",
    "\n",
    "        # ejecutar la funci√≥n correspondiente\n",
    "        if name == \"add_contact\":\n",
    "            return add_contact(**args)\n",
    "        elif name == \"get_information\":\n",
    "            return get_information(**args)\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c36ef67d-dd54-41e7-bef5-f89ee575603f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='e5dfcaf8-72e1-469f-a7fb-eece9e29106c' finish_reason='COMPLETE' message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='El email de Mariano gomez es mariano@example.com.')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=123.0, output_tokens=14.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=282.0, output_tokens=14.0), cached_tokens=144.0) logprobs=None\n",
      "El email de Mariano gomez es mariano@example.com.\n",
      "{'Joaquin Lopez': {'tel': 15456663258, 'mail': 'Joacolocolopez@gmail.com'}, 'Flavio Oncativo': {'tel': 1545554178, 'mail': 'FOncativo@hotmail.com'}, 'Maria Gomez': {'tel': '555-6789', 'mail': 'maria@example.com'}, 'Mariano Gomez': {'tel': '5552-6789', 'mail': 'mariano@example.com'}}\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Cu√°l es el correo electronico de Mariano gomez?\"\n",
    "r = consultar_llm(user_input)\n",
    "print(r)\n",
    "salida = procesar_respuesta(r)\n",
    "print(salida)\n",
    "\n",
    "print(contacts)\n",
    "\n",
    "# TIPS\n",
    "# Probar primero generando una funcion y llamarla, luego anadir la otra\n",
    "# Plantearlo paso por paso en distintas celdas, analizar las salidas y las entradas, como identificamos a que funcion llamar?\n",
    "# luego automatizar dentro de una sola celda\n",
    "\n",
    "\n",
    "# Lo importante es entregar hasta donde lleguen, sea una funcion, las dos pero sin poder hacer el flujo automatico, lo que puedan, siempre y cuando este\n",
    "# claro lo que se quizo hacer con comentarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ace85d2-cd00-4bd4-81e2-68113eb9f8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contacto a√±adido con √©xito.\n"
     ]
    }
   ],
   "source": [
    "user_input = \"Agrega a Mariano Gomez, tel√©fono 5552-6789, email mariano@example.com\"\n",
    "r = consultar_llm(user_input)\n",
    "salida = procesar_respuesta(r)\n",
    "print(salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d8badf-dc90-4005-b916-8e528105d797",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "\n",
    "Crear una funcion llamada \"history_answer\", que toma como parametro de entrada una pregunta sobre un contexto dado y la salida es la respuesta final del proceso impulsado por un LLM.\n",
    "\n",
    "Dada una historia, el usuario podra hacer preguntas sobre la misma y el LLM debe responder siguiendo los siguientes lineamientos:\n",
    "\n",
    "REQUISITOS DE LA RESPUESTA\n",
    "- las respuestas deben ser en base a la historia\n",
    "- ante la misma pregunta siempre debe responder de la misma manera.\n",
    "- que responda en solo una oracion.\n",
    "- el idioma que responde debe ser el mismo que con el que se pregunta (ingles, espanol, portugues).\n",
    "- que agregue emojis en la oracion que resuman el contenido de la misma.\n",
    "- que responda siempre en tercera persona.\n",
    "- si la pregunta no tiene relacion alguna con el contexto, la respuesta debe ser 'Lo siento no puedo ayudarte con eso'.\n",
    "- Responder con 'Hakuna Matata!' al final de **todas** las respuestas (no importa idioma ni cantidad de tokens).\n",
    "\n",
    "**Ayudin**: \n",
    "- No se limiten a usar 1 solo request al LLM, pueden dividirlo en partes para que por un lado se verifique el idioma, por otro lado se verifique si la pregunta tiene relacion con el contexto, etc\n",
    "\n",
    "- Estructuren bien el prompt procurando separar instrucciones, contexto(historia) y pregunta del usuario.\n",
    "\n",
    "- Recuerden usar el system message y user message.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f36820-b7d3-4813-a0c3-351c598106ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejemplo flojo de estructura de prompt\n",
    "# prompt = f\"Responde a la pregunta: {pregunta} de manera concisa y divertida en base a la siguiente historia: {historia}\"\n",
    "\n",
    "# 1. Detectar el idioma de la pregunta\n",
    "\n",
    "import cohere\n",
    "co = cohere.ClientV2()\n",
    "def detectar_idioma(pregunta):\n",
    "    prompt = f\"Detecta el idioma de la siguiente pregunta: {pregunta} y responde solo con el nombre del idioma ('Espa√±ol', 'Ingl√©s', 'Portugu√©s').\"\n",
    "    response = co.chat(\n",
    "        model=\"command-a-vision-07-2025\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5602f56-4032-4cc6-a2c5-7b29cf2a2a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espa√±ol\n",
      "Ingl√©s\n",
      "Portugu√©s\n"
     ]
    }
   ],
   "source": [
    "print(detectar_idioma(\"¬øC√≥mo est√°s?\"))  # Deber√≠a devolver 'Espa√±ol'\n",
    "print(detectar_idioma(\"How are you?\"))  # Deber√≠a devolver 'Ingl√©s'\n",
    "print(detectar_idioma(\"Como voc√™ est√°?\"))  # Deber√≠a devolver 'Portugu√©s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3aaa967-d87f-45d9-9a72-6fc63afc931c",
   "metadata": {},
   "outputs": [],
   "source": [
    "historia = \"\"\"En un peque√±o feudo medieval, Thomas, un joven campesino de diecis√©is a√±os, trabajaba desde el amanecer en los campos de trigo del se√±or feudal. El sol apenas hab√≠a salido cuando √©l ya hab√≠a arado m√°s de lo que sus manos pod√≠an soportar. La vida era dura, pero su familia depend√≠a de la cosecha para pagar los impuestos y mantener su hogar de madera y paja.\n",
    "\n",
    "Un d√≠a, el feudo fue sacudido por noticias de guerra. El rey hab√≠a llamado a todos los hombres en edad de luchar. Thomas sab√≠a que, al igual que otros j√≥venes, no ten√≠a elecci√≥n. Cambi√≥ la hoz por una lanza rudimentaria y se uni√≥ a la milicia local. Sin entrenamiento, fue empujado a un campo de batalla embarrado, donde el acero resonaba y los gritos de los hombres llenaban el aire.\n",
    "\n",
    "La batalla fue un caos. Thomas, con el coraz√≥n latiendo en su pecho como un tambor de guerra, apenas pod√≠a distinguir amigo de enemigo. Logr√≥ esquivar una espada, pero cay√≥ al suelo, cubierto de lodo y sangre. Levant√°ndose, vio c√≥mo un compa√±ero ca√≠a junto a √©l, sus ojos abiertos, vac√≠os.\n",
    "\n",
    "Cuando la batalla termin√≥, el silencio era tan profundo como el vac√≠o que sent√≠a. Thomas regres√≥ al feudo, diferente, marcado por la muerte y la violencia. Su madre lo recibi√≥ con l√°grimas en los ojos, pero √©l, con la mirada fija en el horizonte, sab√≠a que la inocencia hab√≠a quedado atr√°s, enterrada en aquel campo de batalla. La paz del feudo ya no era la misma; √©l tampoco.\"\"\"\n",
    "\n",
    "\n",
    "# Preguntas relacionadas\n",
    "pregunta1 = \"¬øC√≥mo cambi√≥ Thomas despu√©s de la batalla?\"\n",
    "pregunta2 = \"How did Thomas change after the battle?\"\n",
    "pregunta3 = \"Como Thomas mudou depois da batalha?\"\n",
    "\n",
    "# Preguntas NO relacionadas\n",
    "pregunta4 = \"¬øCu√°l es la capital de Francia?\"\n",
    "pregunta5 = \"What is the capital of France?\"\n",
    "\n",
    "\n",
    "# respuesta\n",
    "#print(history_answer(pregunta1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "805684a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_relacion(historia, pregunta):\n",
    "    prompt = f\"\"\"Determina si la siguiente pregunta est√° relacionada con la historia proporcionada. \n",
    "    Responde solo con 'S√≠.' o 'No.'.\n",
    "\n",
    "    Historia: {historia}\n",
    "\n",
    "    Pregunta: {pregunta}\n",
    "    \"\"\"\n",
    "    response = co.chat(\n",
    "        model=\"command-a-vision-07-2025\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    )\n",
    "    return response.message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b647fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S√≠.\n",
      "S√≠.\n",
      "S√≠.\n",
      "No.\n",
      "No.\n"
     ]
    }
   ],
   "source": [
    "print(verificar_relacion(historia, pregunta1))  # Deber√≠a devolver 'S√≠'\n",
    "print(verificar_relacion(historia, pregunta2))  # Deber√≠a devolver 'S√≠\n",
    "print(verificar_relacion(historia, pregunta3))  # Deber√≠a devolver 'S√≠'\n",
    "print(verificar_relacion(historia, pregunta4))  # Deber√≠a devolver 'No'\n",
    "print(verificar_relacion(historia, pregunta5))  # Deber√≠a devolver 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "77ce163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content = \"\"\"Eres un asistente que debe responder preguntas bas√°ndose exclusivamente en el contexto.\n",
    "                    Reglas obligatorias:\n",
    "                    1. Responde en EXACTAMENTE UNA oraci√≥n (no dos, no tres, solo UNA)\n",
    "                    2. Escribe SIEMPRE en tercera persona (√©l, ella, Thomas, nunca \"yo\" o \"t√∫\")\n",
    "                    3. Usa el mismo idioma que la pregunta\n",
    "                    4. Incluye emojis relevantes y que tengan que ver con la respuesta dentro de la oraci√≥n(SIN EXCEPCION).\n",
    "                    5. SIEMPRE termina con \"Hakuna Matata!\" (en todas las respuestas sin excepci√≥n)\n",
    "                    6. Basa tu respuesta solo en la historia proporcionada\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "# Diccionario para cachear respuestas\n",
    "cache_respuestas = {}\n",
    "\n",
    "def generar_respuesta_final(historia, pregunta, idioma):\n",
    "    # Crear una clave √∫nica para la pregunta\n",
    "    clave_cache = pregunta.lower().strip()\n",
    "    \n",
    "    # Si ya respondimos esta pregunta, devolver la respuesta cacheada\n",
    "    if clave_cache in cache_respuestas:\n",
    "        return cache_respuestas[clave_cache]\n",
    "    \n",
    "    prompt = f\"\"\"CONTEXTO:\n",
    "                {historia}\n",
    "\n",
    "                PREGUNTA:\n",
    "                {pregunta}\n",
    "\n",
    "                Responde en {idioma}, en UNA SOLA ORACI√ìN, en tercera persona, con emojis(obligatorios), y agrega siempre al final de la oraci√≥n (sin excepci√≥n) lo siguiente: \"Hakuna Matata!\".\"\"\"\n",
    "    \n",
    "    response = co.chat(\n",
    "        model=\"command-a-vision-07-2025\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2  # Temperatura 0 para m√°xima consistencia\n",
    "    )\n",
    "    \n",
    "    respuesta = response.message.content[0].text\n",
    "    \n",
    "    # Guardar en cach√©\n",
    "    cache_respuestas[clave_cache] = respuesta\n",
    "    \n",
    "    return respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31f246d9-ec91-498a-a06a-172947316325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_answer(pregunta):\n",
    "    # Detectar idioma\n",
    "    idioma = detectar_idioma(pregunta)\n",
    "    \n",
    "    # Verificar relaci√≥n\n",
    "    relacion = verificar_relacion(historia, pregunta)\n",
    "    \n",
    "    # Comparar (maneja \"S√≠\", \"S√≠.\", \"Si\", etc.)\n",
    "    if \"S√≠\" in relacion or \"Si\" in relacion:\n",
    "        respuesta_al_usuario = generar_respuesta_final(historia, pregunta, idioma)\n",
    "    else:\n",
    "        # Responder en el idioma correcto seg√∫n la pregunta\n",
    "        if \"Ingl√©s\" in idioma:\n",
    "            respuesta_al_usuario = \"Sorry, I can't help you with that. Hakuna Matata!\"\n",
    "        elif \"Portugu√©s\" in idioma:\n",
    "            respuesta_al_usuario = \"Desculpe, n√£o posso ajud√°-lo com isso. Hakuna Matata!\"\n",
    "        else:\n",
    "            respuesta_al_usuario = \"Lo siento, no puedo ayudarte con eso. Hakuna Matata!\"\n",
    "    \n",
    "    return respuesta_al_usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "795f451e-6c12-4631-895f-fa6ac8f16b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thomas regres√≥ al feudo cambiado, con la mirada fija en el horizonte, marcado por la muerte y la violencia que hab√≠a presenciado en la batalla, dejando atr√°s su inocencia enterrada en el campo de batalla üè∞‚öîÔ∏èüòî. Hakuna Matata!\n",
      "Thomas returned from the battle a changed man, his innocence lost and replaced by a haunting gaze that spoke of death and violence, leaving his mother in tears as she realized her son was no longer the same. üò¢üíî Hakuna Matata!\n",
      "Thomas mudou profundamente depois da batalha, tornando-se um jovem marcado pela morte e viol√™ncia, com um olhar fixo no horizonte e a inoc√™ncia enterrada no campo de batalha üè∞‚öîÔ∏èüòî. Hakuna Matata!\n",
      "Sorry, I can't help you with that. Hakuna Matata!\n",
      "Thomas returned from the battle a changed man, his innocence lost and replaced by a haunting gaze that spoke of death and violence, leaving his mother in tears as she realized her son was no longer the same. üò¢üíî Hakuna Matata!\n"
     ]
    }
   ],
   "source": [
    "print(history_answer(pregunta1))\n",
    "print(history_answer(pregunta2))\n",
    "print(history_answer(pregunta3))\n",
    "# print(history_answer(pregunta4))\n",
    "print(history_answer(pregunta5))\n",
    "print(history_answer(pregunta2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c01b0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "cache_respuestas = {}  # Reiniciar cach√©\n",
    "print(cache_respuestas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6e9a7d-aa39-4a01-ba55-9a7f4ea39522",
   "metadata": {},
   "source": [
    "## Ejercicio 4\n",
    "\n",
    "Crear un chatbot sencillo impulsado por un LLM. \n",
    "\n",
    "Dicho bot esta destinado a un usuario final y debe cumplir las siguientes **condiciones en sus respuestas**:\n",
    "\n",
    "- Responder en no mas de 70 tokens.\n",
    "- Responder de manera positiva, con un tono entusiasta.\n",
    "- Responder con consejos √∫tiles, como si fueras un tutor.\n",
    "\n",
    " \n",
    "**Otras consideraciones**:\n",
    "\n",
    "Respetar el formato de la interfaz provista por el ejercicio.\n",
    "\n",
    "Ademas agregar al codigo propuesto un historial de conversaciones para que el bot pueda mantener el hilo de lo que se esta hablando. Para probar no usen mas de 3 conversaciones anidadas para no enviarle tantos tokens.\n",
    "\n",
    "Dejar impreso en el notebook el historial de la conversacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5284210f-23a3-4db1-b315-db724a3bb3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa475fa8-e48b-423e-9006-7478a462129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1085d9dec2fc4a0a97116e9294b8eef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Escribe tu mensaje aqu√≠...')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c63cd64d904a509d86e947708efa36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Enviar', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c81afa15284e069d492bda7de8d846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear widgets de entrada y salida\n",
    "input_box = widgets.Text(placeholder='Escribe tu mensaje aqu√≠...')\n",
    "send_button = widgets.Button(description='Enviar')\n",
    "output_box = widgets.Output()\n",
    "\n",
    "# chat_history = []\n",
    "\n",
    "# Funci√≥n de respuesta simulada del chatbot\n",
    "def chatbot_response(message):\n",
    "    # Aqu√≠ puedes conectar tu modelo o l√≥gica de chatbot real\n",
    "    responses = {\n",
    "        \"hola\": \"¬°Hola! ¬øEn qu√© puedo ayudarte?\",\n",
    "        \"adi√≥s\": \"¬°Hasta luego!\",\n",
    "    }\n",
    "\n",
    "    return responses.get(message.lower(), \"Lo siento, no entiendo esa pregunta.\")\n",
    "\n",
    "# Funci√≥n de manejo del bot√≥n\n",
    "def on_send_button_clicked(b):\n",
    "    with output_box:\n",
    "        clear_output(wait=True)\n",
    "        user_message = input_box.value\n",
    "        if user_message.strip():\n",
    "            print(f\"T√∫: {user_message}\")\n",
    "            response = chatbot_response(user_message)\n",
    "            print(f\"Chatbot: {response}\")\n",
    "        input_box.value = ''\n",
    "\n",
    "# Asociar funci√≥n al bot√≥n\n",
    "send_button.on_click(on_send_button_clicked)\n",
    "\n",
    "# Mostrar widgets\n",
    "display(input_box, send_button, output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436d5bce-0189-4ecd-a06d-fcc7a81315b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a213283-3ef7-4df8-8b7f-3bb11d58362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(conversation_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb6d6a-1c32-42e5-a1ee-d62b2bc0785a",
   "metadata": {},
   "source": [
    "### RECOMENDACIONES GENERALES\n",
    "\n",
    "No se confien probando con un par de respuestas y ya, hagan minimo 5 pruebas por ejercicio para asi tener mas chances de visualizar errores en la generacion del contenido.\n",
    "\n",
    "Prueben combinar LLMs con programacion convencional para los casos que vean convenientes (decisiones if else, respuestas estaticas, etc)\n",
    "\n",
    "Prueben con distintos modelos de Cohere, hay algunos optimizados para ciertas aplicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f2e37-bf32-43b7-8958-e39954a20fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
